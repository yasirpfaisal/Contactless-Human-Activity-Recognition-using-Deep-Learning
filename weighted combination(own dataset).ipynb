{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "228b3a62-d86a-4f38-9819-f05c8226d4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 CSV files.\n",
      "\n",
      "üîç Processing file: csi_all_samples_G1_L1.csv\n",
      "Loaded 600015 rows.\n",
      "Found 750 complete samples.\n",
      "\n",
      "üîç Processing file: csi_all_samples_G2_L1.csv\n",
      "Loaded 600015 rows.\n",
      "Found 750 complete samples.\n",
      "\n",
      "üîç Processing file: csi_all_samples_G3_L1.csv\n",
      "Loaded 600013 rows.\n",
      "Found 750 complete samples.\n",
      "\n",
      "üîç Processing file: csi_all_samples_G4_L1.csv\n",
      "Loaded 600015 rows.\n",
      "Found 750 complete samples.\n",
      "\n",
      "üîç Processing file: csi_all_samples_G5_L1.csv\n",
      "Loaded 600649 rows.\n",
      "Found 750 complete samples.\n",
      "\n",
      "üîç Processing file: csi_all_samples_G6_l1.csv\n",
      "Loaded 600014 rows.\n",
      "Found 750 complete samples.\n",
      "\n",
      "üîç Processing file: csi_all_samples_G7_L1.csv\n",
      "Loaded 600015 rows.\n",
      "Found 750 complete samples.\n",
      "\n",
      "üîç Processing file: csi_all_samples_G9_L1.csv\n",
      "Loaded 600014 rows.\n",
      "Found 750 complete samples.\n",
      "\n",
      "üìä Sample counts per (action, coordinate):\n",
      "  (1, '1,1.5'): 408 samples\n",
      "  (1, '3.5,1.5'): 400 samples\n",
      "  (1, '2.75,5.1'): 400 samples\n",
      "  (2, '1,1.5'): 400 samples\n",
      "  (2, '3.5,1.5'): 400 samples\n",
      "  (2, '2.75,5.1'): 400 samples\n",
      "  (3, '1,1.5'): 400 samples\n",
      "  (3, '3.5,1.5'): 400 samples\n",
      "  (3, '2.75,5.1'): 400 samples\n",
      "  (4, '1,1.5'): 400 samples\n",
      "  (4, '3.5,1.5'): 400 samples\n",
      "  (4, '2.75,5.1'): 400 samples\n",
      "  (5, '1,1.5'): 400 samples\n",
      "  (5, '3.5,1.5'): 400 samples\n",
      "  (5, '2.75,5.1'): 392 samples\n",
      "‚úÖ Augmenting class (1, 1,1.5) with 50 samples...\n",
      "‚úÖ Augmenting class (1, 3.5,1.5) with 50 samples...\n",
      "‚úÖ Augmenting class (1, 2.75,5.1) with 50 samples...\n",
      "‚úÖ Augmenting class (2, 1,1.5) with 50 samples...\n",
      "‚úÖ Augmenting class (2, 3.5,1.5) with 50 samples...\n",
      "‚úÖ Augmenting class (2, 2.75,5.1) with 50 samples...\n",
      "‚úÖ Augmenting class (3, 1,1.5) with 50 samples...\n",
      "‚úÖ Augmenting class (3, 3.5,1.5) with 50 samples...\n",
      "‚úÖ Augmenting class (3, 2.75,5.1) with 50 samples...\n",
      "‚úÖ Augmenting class (4, 1,1.5) with 50 samples...\n",
      "‚úÖ Augmenting class (4, 3.5,1.5) with 50 samples...\n",
      "‚úÖ Augmenting class (4, 2.75,5.1) with 50 samples...\n",
      "‚úÖ Augmenting class (5, 1,1.5) with 50 samples...\n",
      "‚úÖ Augmenting class (5, 3.5,1.5) with 50 samples...\n",
      "‚úÖ Augmenting class (5, 2.75,5.1) with 50 samples...\n",
      "\n",
      "‚úÖ Augmented CSV saved with 600000 rows at:\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import random\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "input_dir = r\"C:\\Users\\fdzya\\Desktop\\mmu\\YEAR 4\\fyp\\resources\\own dataset\\samples augment\\real groups\\layout 1\"  # Folder containing G1_layout1.csv ... G10_layout1.csv\n",
    "output_csv = r\"C:\\Users\\fdzya\\Desktop\\mmu\\YEAR 4\\fyp\\resources\\own dataset\\weighted combination\\layout 1\\G15\\augmented_G15_L1.csv\"\n",
    "frames_per_sample = 800\n",
    "samples_per_class = 50\n",
    "num_actions = 5\n",
    "coordinates = [\"1,1.5\", \"3.5,1.5\", \"2.75,5.1\"]\n",
    "\n",
    "# === Load and segment all data ===\n",
    "all_files = glob(os.path.join(input_dir, \"*.csv\"))\n",
    "print(f\"Found {len(all_files)} CSV files.\")\n",
    "\n",
    "class_samples = {}\n",
    "\n",
    "for file in all_files:\n",
    "    print(f\"\\nüîç Processing file: {os.path.basename(file)}\")\n",
    "    try:\n",
    "        df = pd.read_csv(file)\n",
    "        print(f\"Loaded {len(df)} rows.\")\n",
    "\n",
    "        df[\"Coordinates\"] = df[\"Coordinates\"].astype(str).str.replace(\" \", \"\").str.strip()\n",
    "        df[\"Action\"] = df[\"Action\"].astype(int)\n",
    "\n",
    "        total_rows = len(df)\n",
    "        num_samples = total_rows // frames_per_sample\n",
    "        print(f\"Found {num_samples} complete samples.\")\n",
    "\n",
    "        for i in range(num_samples):\n",
    "            start = i * frames_per_sample\n",
    "            end = start + frames_per_sample\n",
    "            sample = df.iloc[start:end]\n",
    "\n",
    "            coord = sample[\"Coordinates\"].iloc[0]\n",
    "            action = sample[\"Action\"].iloc[0]\n",
    "\n",
    "            if (action, coord) not in class_samples:\n",
    "                class_samples[(action, coord)] = []\n",
    "\n",
    "            class_samples[(action, coord)].append(sample)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading {file}: {e}\")\n",
    "\n",
    "# === Print class-wise sample counts ===\n",
    "print(\"\\nüìä Sample counts per (action, coordinate):\")\n",
    "for key, samples in class_samples.items():\n",
    "    print(f\"  {key}: {len(samples)} samples\")\n",
    "\n",
    "# Final fixed augmentation loop\n",
    "augmented_samples = []\n",
    "sample_counter = {}\n",
    "\n",
    "for (action, coord), samples in class_samples.items():\n",
    "    if len(samples) < 2:\n",
    "        print(f\"‚ö†Ô∏è Not enough samples for class ({action}, {coord}). Skipping.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"‚úÖ Augmenting class ({action}, {coord}) with {samples_per_class} samples...\")\n",
    "    for i in range(samples_per_class):\n",
    "        try:\n",
    "            s1, s2 = random.sample(samples, 2)\n",
    "\n",
    "            numeric_cols = s1.select_dtypes(include=[np.number]).columns\n",
    "            s1_values = s1[numeric_cols].values\n",
    "            s2_values = s2[numeric_cols].values\n",
    "\n",
    "            w1 = np.random.uniform(0.2, 0.8)\n",
    "            w2 = 1 - w1\n",
    "            combined_values = w1 * s1_values + w2 * s2_values\n",
    "\n",
    "            combined_df = s1.copy()\n",
    "            combined_df[numeric_cols] = combined_values\n",
    "            combined_df[\"Coordinates\"] = coord\n",
    "            combined_df[\"Action\"] = action\n",
    "\n",
    "            key = (action, coord)\n",
    "            sample_num = sample_counter.get(key, 1)\n",
    "            combined_df[\"Sample\"] = sample_num\n",
    "            sample_counter[key] = sample_num + 1\n",
    "\n",
    "            augmented_samples.append(combined_df)\n",
    "\n",
    "        except Exception as aug_e:\n",
    "            print(f\"‚ùå Error during augmentation: {aug_e}\")\n",
    "            \n",
    "# === Save if any samples were created ===\n",
    "if augmented_samples:\n",
    "    final_df = pd.concat(augmented_samples, axis=0).reset_index(drop=True)\n",
    "    final_df.to_csv(output_csv, index=False)\n",
    "    print(f\"\\n‚úÖ Augmented CSV saved with {len(final_df)} rows at:\")\n",
    "else:\n",
    "    print(\"\\n‚ùå No augmented samples generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "833049a4-bcff-4ce0-ba5b-f3b540e3e95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Frame column fixed and saved to: C:\\Users\\fdzya\\Desktop\\mmu\\YEAR 4\\fyp\\resources\\own dataset\\weighted combination\\layout 1\\G15\\augmented_G15_L1_fixed.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to your CSV file\n",
    "csv_path = r\"C:\\Users\\fdzya\\Desktop\\mmu\\YEAR 4\\fyp\\resources\\own dataset\\weighted combination\\layout 1\\G15\\augmented_G15_L1.csv\"\n",
    "output_path = r\"C:\\Users\\fdzya\\Desktop\\mmu\\YEAR 4\\fyp\\resources\\own dataset\\weighted combination\\layout 1\\G15\\augmented_G15_L1_fixed.csv\"\n",
    "\n",
    "# Load full CSV\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "frames_per_sample = 800\n",
    "num_samples = len(df) // frames_per_sample\n",
    "\n",
    "# Fix the Frame column\n",
    "corrected_frames = []\n",
    "\n",
    "for i in range(num_samples):\n",
    "    corrected_frames.extend(range(1, frames_per_sample + 1))\n",
    "\n",
    "# If any leftover rows (incomplete sample), retain original values\n",
    "remainder = len(df) % frames_per_sample\n",
    "if remainder:\n",
    "    corrected_frames.extend(df[\"Frame\"].iloc[-remainder:].tolist())\n",
    "\n",
    "# Replace and save\n",
    "df[\"Frame\"] = corrected_frames\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Frame column fixed and saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5e5419-8aee-42bf-a274-1a406c35e0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIGURABLE SCALING FACTORS ===\n",
    "amp_scaling_factor = 0.9     # e.g., 0.9 means reduce amplitude\n",
    "phase_scaling_factor = 1.1   # e.g., 1.1 means increase phase\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import random\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "input_dir = r\"C:\\Users\\fdzya\\Desktop\\mmu\\YEAR 4\\fyp\\resources\\own dataset\\samples augment\\real groups\\layout 1\\csi_all_samples\"  # Folder containing G1_layout1.csv ... G10_layout1.csv\n",
    "output_csv = r\"C:\\Users\\fdzya\\Desktop\\mmu\\YEAR 4\\fyp\\resources\\own dataset\\weighted combination\\layout 1\\G15\\augmented_G15_L1.csv\"\n",
    "frames_per_sample = 800\n",
    "samples_per_class = 50\n",
    "num_actions = 5\n",
    "coordinates = [\"1,1.5\", \"3.5,1.5\", \"2.75,5.1\"]\n",
    "\n",
    "# === Load and segment all data ===\n",
    "all_files = glob(os.path.join(input_dir, \"*.csv\"))\n",
    "print(f\"Found {len(all_files)} CSV files.\")\n",
    "\n",
    "class_samples = {}\n",
    "\n",
    "for file in all_files:\n",
    "    print(f\"\\nüîç Processing file: {os.path.basename(file)}\")\n",
    "    try:\n",
    "        df = pd.read_csv(file)\n",
    "        print(f\"Loaded {len(df)} rows.\")\n",
    "\n",
    "        df[\"Coordinates\"] = df[\"Coordinates\"].astype(str).str.replace(\" \", \"\").str.strip()\n",
    "        df[\"Action\"] = df[\"Action\"].astype(int)\n",
    "\n",
    "        total_rows = len(df)\n",
    "        num_samples = total_rows // frames_per_sample\n",
    "        print(f\"Found {num_samples} complete samples.\")\n",
    "\n",
    "        for i in range(num_samples):\n",
    "            start = i * frames_per_sample\n",
    "            end = start + frames_per_sample\n",
    "            sample = df.iloc[start:end]\n",
    "\n",
    "            coord = sample[\"Coordinates\"].iloc[0]\n",
    "            action = sample[\"Action\"].iloc[0]\n",
    "\n",
    "            if (action, coord) not in class_samples:\n",
    "                class_samples[(action, coord)] = []\n",
    "\n",
    "            class_samples[(action, coord)].append(sample)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading {file}: {e}\")\n",
    "\n",
    "# === Print class-wise sample counts ===\n",
    "print(\"\\nüìä Sample counts per (action, coordinate):\")\n",
    "for key, samples in class_samples.items():\n",
    "    print(f\"  {key}: {len(samples)} samples\")\n",
    "\n",
    "\n",
    "# Final fixed augmentation loop with scaling\n",
    "augmented_samples = []\n",
    "sample_counter = {}\n",
    "\n",
    "for (action, coord), samples in class_samples.items():\n",
    "    if len(samples) < 2:\n",
    "        print(f\"‚ö†Ô∏è Not enough samples for class ({action}, {coord}). Skipping.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"‚úÖ Augmenting class ({action}, {coord}) with {samples_per_class} samples...\")\n",
    "    for i in range(samples_per_class):\n",
    "        try:\n",
    "            s1, s2 = random.sample(samples, 2)\n",
    "\n",
    "            numeric_cols = s1.select_dtypes(include=[np.number]).columns\n",
    "            s1_values = s1[numeric_cols].values\n",
    "            s2_values = s2[numeric_cols].values\n",
    "\n",
    "            w1 = np.random.uniform(0.2, 0.8)\n",
    "            w2 = 1 - w1\n",
    "            combined_values = w1 * s1_values + w2 * s2_values\n",
    "\n",
    "            # Apply scaling\n",
    "            amp_cols = [col for col in numeric_cols if col.startswith(\"Amp_dBm[\")]\n",
    "            phase_cols = [col for col in numeric_cols if col.startswith(\"Phase_deg[\")]\n",
    "\n",
    "            amp_indices = [numeric_cols.get_loc(c) for c in amp_cols]\n",
    "            phase_indices = [numeric_cols.get_loc(c) for c in phase_cols]\n",
    "\n",
    "            combined_values[:, amp_indices] *= amp_scaling_factor\n",
    "            combined_values[:, phase_indices] *= phase_scaling_factor\n",
    "\n",
    "            # Build final DataFrame\n",
    "            combined_df = s1.copy()\n",
    "            combined_df[numeric_cols] = combined_values\n",
    "            combined_df[\"Coordinates\"] = coord\n",
    "            combined_df[\"Action\"] = action\n",
    "\n",
    "            key = (action, coord)\n",
    "            sample_num = sample_counter.get(key, 1)\n",
    "            combined_df[\"Sample\"] = sample_num\n",
    "            sample_counter[key] = sample_num + 1\n",
    "\n",
    "            augmented_samples.append(combined_df)\n",
    "\n",
    "        except Exception as aug_e:\n",
    "            print(f\"‚ùå Error during augmentation: {aug_e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3295e28-782a-4c98-8cff-fecd38186b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved scaled CSV to: C:\\Users\\fdzya\\Desktop\\mmu\\YEAR 4\\fyp\\resources\\own dataset\\amplitude phase scaling\\G15\\layout 1\\csi_all_samples_G15_L1.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "input_file =  r\"C:\\Users\\fdzya\\Desktop\\mmu\\YEAR 4\\fyp\\resources\\own dataset\\samples\\G9\\layout 1\\csi_all_samples_G9_L1.csv\"          # Folder with G1_L1.csv to G8_L1.csv\n",
    "output_file = r\"C:\\Users\\fdzya\\Desktop\\mmu\\YEAR 4\\fyp\\resources\\own dataset\\amplitude phase scaling\\G15\\layout 1\\csi_all_samples_G15_L1.csv\"       # Where to save G9‚ÄìG16 augmented files\n",
    "amp_scaling = 0.95\n",
    "phase_scaling = 1.05\n",
    "\n",
    "# === Load and Scale ===\n",
    "df = pd.read_csv(input_file)\n",
    "amp_cols = [col for col in df.columns if col.startswith(\"Amp_dBm[\")]\n",
    "phase_cols = [col for col in df.columns if col.startswith(\"Phase_deg[\")]\n",
    "\n",
    "df[amp_cols] *= amp_scaling\n",
    "df[phase_cols] *= phase_scaling\n",
    "\n",
    "# === Save\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"‚úÖ Saved scaled CSV to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21b5ed3-4999-4aef-89fb-c410cba3c54c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
