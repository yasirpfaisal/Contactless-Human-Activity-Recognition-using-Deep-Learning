{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5c5e21-77ee-4158-abed-c48c8446bd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense, Dropout, Input, LeakyReLU, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Input\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import regularizers\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import keras.metrics as metrics\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import time\n",
    "from keras.regularizers import l2\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d70125e-dea8-4278-aa08-7c2c7f61b27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ensure inline plotting\n",
    "%matplotlib inline\n",
    "\n",
    "# Set dataset paths\n",
    "train_path = r'C:\\Users\\fdzya\\Desktop\\mmu\\YEAR 4\\fyp\\resources\\own dataset\\sample images\\5 classes\\All layouts\\train'\n",
    "test_path = r'C:\\Users\\fdzya\\Desktop\\mmu\\YEAR 4\\fyp\\resources\\own dataset\\sample images\\5 classes\\All layouts\\test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c33e1f-5c04-40d8-8fd3-d56c60d1aee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare image data generators with augmentation for the training set\n",
    "train_datagen = ImageDataGenerator(featurewise_center=False)\n",
    "\n",
    "# Keep the test set generator simple (no augmentation)\n",
    "test_datagen = ImageDataGenerator(featurewise_center=False)\n",
    "\n",
    "train_set = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(64, 64),\n",
    "    color_mode=\"rgb\",\n",
    "    classes=['action_1', 'action_2', 'action_3', 'action_4', 'action_5'],\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=256,\n",
    "    interpolation=\"nearest\"\n",
    ")\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(64, 64),\n",
    "    color_mode=\"rgb\",\n",
    "    classes=['action_1', 'action_2', 'action_3', 'action_4', 'action_5'],\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=256,\n",
    "    interpolation=\"nearest\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6aff70-4903-4029-9606-a83d8ae2d229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the CNN\n",
    "Classifier = Sequential()\n",
    "\n",
    "# Add Input layer\n",
    "Classifier.add(Input(shape=(64, 64, 3)))\n",
    "\n",
    "# First Convolutional Layer\n",
    "Classifier.add(Convolution2D(32, (3, 3)))  # Add convolutional layer\n",
    "Classifier.add(LeakyReLU(alpha=0.1))  # Use LeakyReLU activation\n",
    "Classifier.add(BatchNormalization())\n",
    "Classifier.add(MaxPooling2D(pool_size=(2, 2)))  # Add max pooling layer\n",
    "Classifier.add(Dropout(0.2))\n",
    "\n",
    "# Second Convolutional Layer\n",
    "Classifier.add(Convolution2D(64, (3, 3)))  # Add another convolutional layerClassifier.add(BatchNormalization())\n",
    "Classifier.add(LeakyReLU(alpha=0.1))  # Use LeakyReLU activation\n",
    "Classifier.add(BatchNormalization())\n",
    "Classifier.add(MaxPooling2D(pool_size=(2, 2)))  # Add another max pooling layer\n",
    "Classifier.add(Dropout(0.35))\n",
    "\n",
    "# third Convolutional Layer\n",
    "Classifier.add(Convolution2D(128, (3, 3)))  # Add another convolutional layer\n",
    "Classifier.add(LeakyReLU(alpha=0.1))  # Use LeakyReLU activation\n",
    "Classifier.add(BatchNormalization())\n",
    "Classifier.add(MaxPooling2D(pool_size=(2, 2)))  # Add another max pooling layer\n",
    "Classifier.add(Dropout(0.5))\n",
    "         \n",
    "# Step 5 - Flattening\n",
    "Classifier.add(Flatten())  # Flatten the feature maps into a 1D vector\n",
    "\n",
    "# Step 6 - Full Connection\n",
    "Classifier.add(Dense(128, activation = 'linear')) # Fully connected layer with linear activation\n",
    "Classifier.add(LeakyReLU(alpha=0.1))  # Use LeakyReLU activation\n",
    "Classifier.add(Dropout(0.5))\n",
    "Classifier.add(Dense(5, activation = 'softmax'))  # Output layer with softmax activation (7 classes)\n",
    "\n",
    "# Step 7 - Compiling the CNN\n",
    "opt = Adam(learning_rate=0.001)  # Adam optimizer with a learning rate of 0.0001\n",
    "Classifier.compile(optimizer=opt,\n",
    "                   loss='categorical_crossentropy',  # Loss function for multi-class classification\n",
    "                   metrics=['accuracy'])  # Track accuracy during training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff360e2-9f02-45db-9da4-01da4b085f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# Callback for ReduceLROnPlateau\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss',  # Metric to monitor\n",
    "                               factor=0.5,          # Factor by which to reduce LR\n",
    "                               patience=3,          # Patience before reducing LR\n",
    "                               min_lr=1e-6,         # Minimum learning rate\n",
    "                               verbose=1)           # Print when LR is reduced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322779a3-a389-4a91-9b7f-24b5620c966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bff5f19-c386-4d46-8684-f734c5ccd4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best model checkpoint\n",
    "checkpoint = ModelCheckpoint(\"model_weights.h5.keras\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a9b145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# === Start Training ===\n",
    "print(\"‚è≥ Starting training...\")\n",
    "train_start_time = time.time()\n",
    "\n",
    "history = Classifier.fit(\n",
    "    train_set,\n",
    "    epochs=100,\n",
    "    validation_data=test_set,\n",
    "    callbacks=[lr_reducer, checkpoint, early_stopping],\n",
    "    verbose=0  # suppress output\n",
    ")\n",
    "\n",
    "train_end_time = time.time()\n",
    "total_training_time = train_end_time - train_start_time\n",
    "\n",
    "# === Evaluate Train Set ===\n",
    "train_eval_start = time.time()\n",
    "train_loss, train_accuracy = Classifier.evaluate(train_set, verbose=0)\n",
    "train_predictions = Classifier.predict(train_set, verbose=0)\n",
    "train_labels = train_set.labels\n",
    "train_predicted_classes = np.argmax(train_predictions, axis=1)\n",
    "\n",
    "train_precision = precision_score(train_labels, train_predicted_classes, average='weighted')\n",
    "train_recall = recall_score(train_labels, train_predicted_classes, average='weighted')\n",
    "train_f1 = f1_score(train_labels, train_predicted_classes, average='weighted')\n",
    "train_eval_time = time.time() - train_eval_start\n",
    "\n",
    "# === Evaluate Test Set ===\n",
    "test_eval_start = time.time()\n",
    "test_loss, test_accuracy = Classifier.evaluate(test_set, verbose=0)\n",
    "test_predictions = Classifier.predict(test_set, verbose=0)\n",
    "test_labels = test_set.labels\n",
    "test_predicted_classes = np.argmax(test_predictions, axis=1)\n",
    "\n",
    "test_precision = precision_score(test_labels, test_predicted_classes, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predicted_classes, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predicted_classes, average='weighted')\n",
    "test_eval_time = time.time() - test_eval_start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0467aa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Final Report ===\n",
    "print(\"\\nüìä Final Evaluation Summary\")\n",
    "\n",
    "print(\"\\n‚úÖ Training Set:\")\n",
    "print(f\"Accuracy   : {train_accuracy * 100:.2f}%\")\n",
    "print(f\"Precision  : {train_precision:.4f}\")\n",
    "print(f\"Recall     : {train_recall:.4f}\")\n",
    "print(f\"F1 Score   : {train_f1:.4f}\")\n",
    "print(f\"Eval Time  : {train_eval_time:.2f} seconds\")\n",
    "\n",
    "print(\"\\n‚úÖ Testing Set:\")\n",
    "print(f\"Accuracy   : {test_accuracy * 100:.2f}%\")\n",
    "print(f\"Precision  : {test_precision:.4f}\")\n",
    "print(f\"Recall     : {test_recall:.4f}\")\n",
    "print(f\"F1 Score   : {test_f1:.4f}\")\n",
    "print(f\"Eval Time  : {test_eval_time:.2f} seconds\")\n",
    "\n",
    "print(f\"\\nüïí Total Training Time: {total_training_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24f72d0-7639-45f8-845d-6b1425743c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "# Evaluate and measure metrics for testing set\n",
    "print(\"Evaluating the testing set...\")\n",
    "start_time = time.time()\n",
    "\n",
    "test_loss, test_accuracy = Classifier.evaluate(test_set, verbose=2)\n",
    "test_predictions = Classifier.predict(test_set, verbose=2)\n",
    "test_labels = test_set.labels\n",
    "test_predicted_classes = np.argmax(test_predictions, axis=1)\n",
    "\n",
    "test_precision = precision_score(test_labels, test_predicted_classes, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predicted_classes, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predicted_classes, average='weighted')\n",
    "\n",
    "end_time = time.time()\n",
    "test_execution_time = end_time - start_time\n",
    "\n",
    "print(\"\\nTesting Results:\")\n",
    "print(f\"Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {test_precision:.2f}\")\n",
    "print(f\"Recall: {test_recall:.2f}\")\n",
    "print(f\"F1 Score: {test_f1:.2f}\")\n",
    "print(f\"Execution Time: {test_execution_time:.2f} seconds\")\n",
    "\n",
    "# Evaluate and measure metrics for training set\n",
    "print(\"\\nEvaluating the training set...\")\n",
    "start_time = time.time()\n",
    "\n",
    "train_loss, train_accuracy = Classifier.evaluate(train_set, verbose=2)\n",
    "train_predictions = Classifier.predict(train_set, verbose=2)\n",
    "train_labels = train_set.labels\n",
    "train_predicted_classes = np.argmax(train_predictions, axis=1)\n",
    "\n",
    "train_precision = precision_score(train_labels, train_predicted_classes, average='weighted')\n",
    "train_recall = recall_score(train_labels, train_predicted_classes, average='weighted')\n",
    "train_f1 = f1_score(train_labels, train_predicted_classes, average='weighted')\n",
    "\n",
    "end_time = time.time()\n",
    "train_execution_time = end_time - start_time\n",
    "\n",
    "print(\"\\nTraining Results:\")\n",
    "print(f\"Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {train_precision:.2f}\")\n",
    "print(f\"Recall: {train_recall:.2f}\")\n",
    "print(f\"F1 Score: {train_f1:.2f}\")\n",
    "print(f\"Execution Time: {train_execution_time:.2f} seconds\")\n",
    "\n",
    "train_end_time = time.time()\n",
    "train_time = train_end_time - train_start_time\n",
    "print(f\"\\nTraining completed in {train_time:.2f} seconds.\")\n",
    "\n",
    "# Measure testing time\n",
    "print(\"\\nStarting testing...\")\n",
    "test_start_time = time.time()\n",
    "\n",
    "test_loss, test_accuracy = Classifier.evaluate(test_set, verbose=2)\n",
    "\n",
    "test_end_time = time.time()\n",
    "test_time = test_end_time - test_start_time\n",
    "print(f\"\\nTesting completed in {test_time:.2f} seconds.\")\n",
    "\n",
    "# Print test accuracy\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf6e8ee-7b97-4582-9864-0671e034d574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot Training vs Validation Accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Test Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Testing Accuracy over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8f2f23-6b84-4b44-a926-f6d030ea05cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Ground truth labels from the test set\n",
    "y_true = test_set.classes\n",
    "\n",
    "# Get class names in order\n",
    "class_names = ['highfive', 'handshake', 'kick left leg', 'punch right fist', 'push']\n",
    "\n",
    "# Predict probabilities\n",
    "y_pred_probs = Classifier.predict(test_set)\n",
    "\n",
    "# Convert probabilities to predicted class indices\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Display the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "fig, ax = plt.subplots(figsize=(8, 6))  # Create figure and axes\n",
    "disp.plot(cmap='Blues', values_format='d', ax=ax)  # Plot on specific axes\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
